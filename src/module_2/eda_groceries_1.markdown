---
jupyter:
  kernelspec:
    display_name: zrive-ds-yVHW3Yen-py3.11
    language: python
    name: python3
  language_info:
    codemirror_mode:
      name: ipython
      version: 3
    file_extension: .py
    mimetype: text/x-python
    name: python
    nbconvert_exporter: python
    pygments_lexer: ipython3
    version: 3.11.0
  nbformat: 4
  nbformat_minor: 5
---

::: {#de391438 .cell .markdown}
# An치lisis Exploratorio de Datos (EDA) - Groceries E-commerce
:::

::: {#046253c2 .cell .markdown}
Este notebook contiene el an치lisis exploratorio inicial de los datos de
una plataforma de e-commerce de alimentaci칩n.
:::

::: {#216c2b65 .cell .markdown}
## Configuraci칩n Inicial
:::

::: {#a6c1ec6d .cell .code execution_count="100"}
``` python
# Imports necesarios
import os
import boto3
from dotenv import load_dotenv
import pathlib
import pandas as pd
import fastparquet as fp
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import seaborn as sns
from datetime import datetime, timedelta
from typing import Optional, Tuple, List, Dict, Any
import calendar
from itertools import chain
from collections import Counter

# Configuraci칩n de estilo
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# Cargar variables de entorno
load_dotenv()
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
S3_PATH = "s3://zrive-ds-data/groceries/sampled-datasets/"
LOCAL_DATA_PATH = 'groceries_data/'
```
:::

::: {#a8b3134f .cell .markdown}
## 1. Carga de Datos {#1-carga-de-datos}
:::

::: {#f75cc175 .cell .code execution_count="101"}
``` python
def download_grocery_data(aws_url: str, local_path: str) -> None:
    """Descarga datos de S3 si no existen localmente."""
    pathlib.Path(local_path).mkdir(parents=True, exist_ok=True)
    
    s3 = boto3.client('s3',
                     aws_access_key_id=AWS_ACCESS_KEY_ID,
                     aws_secret_access_key=AWS_SECRET_ACCESS_KEY)
    
    bucket_name = aws_url.split('/')[2]
    prefix = '/'.join(aws_url.split('/')[3:])
    
    try:
        response = s3.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
        if 'Contents' not in response:
            print("No se encontraron archivos en S3")
            return
            
        for obj in response['Contents']:
            file_key = obj['Key']
            file_name = os.path.basename(file_key)
            local_file_path = os.path.join(local_path, file_name)
            
            print(f"Descargando {file_key} a {local_file_path}")
            s3.download_file(bucket_name, file_key, local_file_path)
    except Exception as e:
        print(f"Error al descargar: {e}")

def get_grocery_file(file: str = 'orders.parquet') -> pd.DataFrame:
    """Obtiene archivo de datos, descarg치ndolo si es necesario."""
    file_path = os.path.join(LOCAL_DATA_PATH, file)
    
    if not os.path.isfile(file_path):
        download_grocery_data(S3_PATH, LOCAL_DATA_PATH)
    else:
        print(f"Archivo {file} ya existe localmente.")
        
    return pd.read_parquet(file_path, engine='fastparquet')

# Cargar todos los datasets
datasets = ['orders.parquet', 'regulars.parquet', 'abandoned_carts.parquet', 
           'inventory.parquet', 'users.parquet']

dfs = {}
for dataset in datasets:
    dfs[dataset.split('.')[0]] = get_grocery_file(dataset)
    
orders_df = dfs['orders']
regulars_df = dfs['regulars']
abandoned_carts_df = dfs['abandoned_carts']
inventory_df = dfs['inventory']
users_df = dfs['users']
```

::: {.output .stream .stdout}
    Archivo orders.parquet ya existe localmente.
    Archivo regulars.parquet ya existe localmente.
    Archivo abandoned_carts.parquet ya existe localmente.
    Archivo inventory.parquet ya existe localmente.
    Archivo users.parquet ya existe localmente.
:::
:::

::: {#813eadd6 .cell .markdown}
## 2. Exploraci칩n de Datos {#2-exploraci칩n-de-datos}
:::

::: {#4352c2d6 .cell .markdown}
### 2.1. Visi칩n General de los Datasets {#21-visi칩n-general-de-los-datasets}
:::

::: {#daaa123f .cell .code execution_count="102"}
``` python
# Dimensiones y columnas de cada dataset
for name, df in dfs.items():
    print(f"\n{name.upper()}")
    print(f"Dimensiones: {df.shape}")
    print(f"Columnas: {', '.join(df.columns)}")
    print("-" * 50)
```

::: {.output .stream .stdout}

    ORDERS
    Dimensiones: (8773, 6)
    Columnas: id, user_id, created_at, order_date, user_order_seq, ordered_items
    --------------------------------------------------

    REGULARS
    Dimensiones: (18105, 3)
    Columnas: user_id, variant_id, created_at
    --------------------------------------------------

    ABANDONED_CARTS
    Dimensiones: (5457, 4)
    Columnas: id, user_id, created_at, variant_id
    --------------------------------------------------

    INVENTORY
    Dimensiones: (1733, 6)
    Columnas: variant_id, price, compare_at_price, vendor, product_type, tags
    --------------------------------------------------

    USERS
    Dimensiones: (4983, 10)
    Columnas: user_id, user_segment, user_nuts1, first_ordered_at, customer_cohort_month, count_people, count_adults, count_children, count_babies, count_pets
    --------------------------------------------------
:::
:::

::: {#5ec35a48 .cell .markdown}
## 2.2. An치lisis de IDs de Items {#22-an치lisis-de-ids-de-items}
:::

::: {#c57cd77f .cell .markdown}
Un aspecto importante es entender la relaci칩n entre los item_id (en
orders) y variant_id (en inventory). Tras investigar, determin칠 que son
conceptos equivalentes - representan la misma entidad de producto.
:::

::: {#97eefcd6 .cell .code execution_count="103"}
``` python
all_ordered_items = list(chain.from_iterable(orders_df['ordered_items']))
ordered_item_ids = set(all_ordered_items)

inventory_item_ids = set(inventory_df['variant_id'])

print(f"Items 칰nicos en orders: {len(ordered_item_ids):,}")
print(f"Items 칰nicos en inventory: {len(inventory_item_ids):,}")

missing_items = ordered_item_ids - inventory_item_ids
print(f"Items en orders sin informaci칩n en inventory: {len(missing_items):,}")
print(f"Porcentaje de items sin info: {len(missing_items)/len(ordered_item_ids)*100:.1f}%")
```

::: {.output .stream .stdout}
    Items 칰nicos en orders: 2,117
    Items 칰nicos en inventory: 1,733
    Items en orders sin informaci칩n en inventory: 640
    Porcentaje de items sin info: 30.2%
:::
:::

::: {#c77c25ad .cell .markdown}
## 2.3. An치lisis de Pedidos {#23-an치lisis-de-pedidos}
:::

::: {#31924160 .cell .code execution_count="104"}
``` python
# A침adir columna con n칰mero de items por pedido
orders_df['num_items'] = orders_df['ordered_items'].apply(len)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# Histograma
ax1.hist(orders_df['num_items'], bins=50, edgecolor='black', alpha=0.7)
ax1.set_title('Distribuci칩n de Items por Pedido', fontsize=14)
ax1.set_xlabel('N칰mero de Items')
ax1.set_ylabel('Frecuencia')

# Boxplot
sns.boxplot(data=orders_df, x='num_items', ax=ax2)
ax2.set_title('Boxplot: Items por Pedido', fontsize=14)
ax2.set_xlabel('N칰mero de Items')

plt.tight_layout()
plt.show()

print("\nEstad칤sticas de items por pedido:")
print(orders_df['num_items'].describe())
```

::: {.output .display_data}
![](vertopal_14d689f6814c4519ba3c7ab29e27ed07/8445c795c793c4427ef11aed2e775ebef8ccac7a.png)
:::

::: {.output .stream .stdout}

    Estad칤sticas de items por pedido:
    count    8773.000000
    mean       12.305711
    std         6.839507
    min         1.000000
    25%         8.000000
    50%        11.000000
    75%        15.000000
    max       114.000000
    Name: num_items, dtype: float64
:::
:::

::: {#a665e388 .cell .markdown}
## 2.4. Patrones Temporales {#24-patrones-temporales}
:::

::: {#5cd14960 .cell .code execution_count="105"}
``` python
# 칍rdenes por d칤a
orders_per_day = orders_df.groupby('order_date').size()

# Visualizaci칩n de serie temporal
plt.figure(figsize=(15, 6))
plt.plot(orders_per_day.index, orders_per_day.values, linewidth=1.5)
plt.title('Evoluci칩n de 칍rdenes Diarias', fontsize=14)
plt.xlabel('Fecha')
plt.ylabel('N칰mero de 칍rdenes')
plt.grid(True, alpha=0.3)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Identificar d칤a con m치s 칩rdenes
max_day = orders_per_day.idxmax()
print(f"\nD칤a con m치s 칩rdenes: {max_day.date()} ({orders_per_day.max()} 칩rdenes)")

# An치lisis por d칤a de la semana
orders_df['weekday'] = pd.to_datetime(orders_df['order_date']).dt.day_name()
weekday_counts = orders_df['weekday'].value_counts().reindex([
    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'
])

plt.figure(figsize=(10, 6))
weekday_counts.plot(kind='bar')
plt.title('Pedidos por D칤a de la Semana', fontsize=14)
plt.xlabel('D칤a')
plt.ylabel('N칰mero de Pedidos')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```

::: {.output .display_data}
![](vertopal_14d689f6814c4519ba3c7ab29e27ed07/6007243cb771e12682f9457ea9118b9754c2a4ab.png)
:::

::: {.output .stream .stdout}

    D칤a con m치s 칩rdenes: 2022-01-21 (199 칩rdenes)
:::

::: {.output .display_data}
![](vertopal_14d689f6814c4519ba3c7ab29e27ed07/085a33a093e4a7f6cd8455ab1a2155b236656f0b.png)
:::
:::

::: {#abc44052 .cell .markdown}
## 2.5. An치lisis de Inventario {#25-an치lisis-de-inventario}
:::

::: {#4c59b373 .cell .code execution_count="106"}
``` python
# Estad칤sticas de precios
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Distribuci칩n de precios
axes[0,0].hist(inventory_df['price'], bins=50, edgecolor='black', alpha=0.7)
axes[0,0].set_title('Distribuci칩n de Precios')
axes[0,0].set_xlabel('Precio (춲)')
axes[0,0].set_ylabel('Frecuencia')

# Relaci칩n precio vs precio comparado
axes[0,1].scatter(inventory_df['price'], inventory_df['compare_at_price'], alpha=0.5)
axes[0,1].plot([0, 30], [0, 30], 'r--', label='L칤nea 1:1')
axes[0,1].set_xlabel('Precio')
axes[0,1].set_ylabel('Precio Original')
axes[0,1].set_title('Precio vs Precio Original')
axes[0,1].legend()

# Categor칤as m치s comunes
top_categories = inventory_df['product_type'].value_counts().head(10)
axes[1,0].barh(top_categories.index[::-1], top_categories.values[::-1])
axes[1,0].set_title('Top 10 Categor칤as de Productos')
axes[1,0].set_xlabel('Cantidad')

# Descuentos por categor칤a
inventory_df['discount_percent'] = np.where(
    (inventory_df['compare_at_price'] > 0) & (inventory_df['price'] > 0),
    ((inventory_df['compare_at_price'] - inventory_df['price']) / inventory_df['compare_at_price']) * 100,
    0
)

category_discounts = inventory_df.groupby('product_type')['discount_percent'].mean().sort_values(ascending=False).head(10)
axes[1,1].barh(category_discounts.index[::-1], category_discounts.values[::-1])
axes[1,1].set_title('Descuento Promedio por Categor칤a')
axes[1,1].set_xlabel('Descuento (%)')

plt.tight_layout()
plt.show()
```

::: {.output .display_data}
![](vertopal_14d689f6814c4519ba3c7ab29e27ed07/265872adb9c8cdbf07263d746aaf932379409f1c.png)
:::
:::

::: {#16e62d2b .cell .markdown}
## 2.6. An치lisis de Usuarios {#26-an치lisis-de-usuarios}
:::

::: {#8b7db7a9 .cell .code execution_count="107"}
``` python
# Distribuci칩n de segmentos de usuario
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Segmentos
segment_counts = users_df['user_segment'].value_counts()
axes[0].pie(segment_counts.values, labels=segment_counts.index, autopct='%1.1f%%')
axes[0].set_title('Distribuci칩n de Segmentos de Usuario')

# Regiones NUTS1
nuts1_counts = users_df['user_nuts1'].value_counts()
axes[1].bar(nuts1_counts.index, nuts1_counts.values)
axes[1].set_title('Distribuci칩n por Regi칩n')
axes[1].set_xlabel('Regi칩n NUTS1')
axes[1].set_ylabel('N칰mero de Usuarios')

plt.tight_layout()
plt.show()

# An치lisis de campos faltantes en datos demogr치ficos
demo_columns = ['count_people', 'count_adults', 'count_children', 'count_babies', 'count_pets']
missing_pct = users_df[demo_columns].isna().mean() * 100

print("\nPorcentaje de valores faltantes en datos demogr치ficos:")
for col, pct in missing_pct.items():
    print(f"{col}: {pct:.1f}%")
```

::: {.output .display_data}
![](vertopal_14d689f6814c4519ba3c7ab29e27ed07/811434097a1782cbb0d5aa6b37a806b36ed4f3f0.png)
:::

::: {.output .stream .stdout}

    Porcentaje de valores faltantes en datos demogr치ficos:
    count_people: 93.5%
    count_adults: 93.5%
    count_children: 93.5%
    count_babies: 93.5%
    count_pets: 93.5%
:::
:::

::: {#0433d924 .cell .code execution_count="108"}
``` python
# An치lisis de patrones de valores faltantes en datos demogr치ficos
demo_columns = ['count_people', 'count_adults', 'count_children', 'count_babies', 'count_pets']

# Contar NaNs por usuario en las columnas demogr치ficas
users_df['nans_in_group'] = users_df[demo_columns].isna().sum(axis=1)

# Visualizar la distribuci칩n
plt.figure(figsize=(10, 6))
nans_distribution = users_df['nans_in_group'].value_counts().sort_index()
bars = nans_distribution.plot(kind='bar', color=['#1f77b4' if x in [0, 5] else '#ff7f0e' for x in nans_distribution.index])
plt.title('Distribuci칩n de Usuarios por Columnas Demogr치ficas Faltantes', fontsize=14)
plt.xlabel('N칰mero de Columnas con NaN')
plt.ylabel('Cantidad de Usuarios')
plt.xticks(rotation=0)

# A침adir etiquetas a las barras
for bar in bars.patches:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2., height,
             f'{int(height)}', ha='center', va='bottom')

plt.tight_layout()
plt.show()

# Resumen del patr칩n
print("\nPatr칩n de valores faltantes en datos demogr치ficos:")
print(f"Usuarios con TODOS los campos demogr치ficos faltantes: {sum(users_df['nans_in_group'] == 5):,}")
print(f"Usuarios con TODOS los campos demogr치ficos completos: {sum(users_df['nans_in_group'] == 0):,}")  
print(f"Usuarios con datos parciales: {sum((users_df['nans_in_group'] > 0) & (users_df['nans_in_group'] < 5)):,}")

# Conclusi칩n sobre imputaci칩n
print("\n游댌 Hallazgo importante:")
print("Los datos demogr치ficos siguen un patr칩n de 'todo o nada':")
print("- O el usuario tiene TODOS los campos demogr치ficos completos")
print("- O el usuario tiene TODOS los campos demogr치ficos vac칤os (NaN)")
print("- NO existen usuarios con datos parcialmente completados")
print("\n丘멆잺 Implicaci칩n: La imputaci칩n de estos valores podr칤a ser problem치tica")
print("   debido a que el 93% de los usuarios no proporcionaron esta informaci칩n.")
```

::: {.output .display_data}
![](vertopal_14d689f6814c4519ba3c7ab29e27ed07/e6674912e810da056960a8dcb1479fc6f163ee85.png)
:::

::: {.output .stream .stdout}

    Patr칩n de valores faltantes en datos demogr치ficos:
    Usuarios con TODOS los campos demogr치ficos faltantes: 4,658
    Usuarios con TODOS los campos demogr치ficos completos: 325
    Usuarios con datos parciales: 0

    游댌 Hallazgo importante:
    Los datos demogr치ficos siguen un patr칩n de 'todo o nada':
    - O el usuario tiene TODOS los campos demogr치ficos completos
    - O el usuario tiene TODOS los campos demogr치ficos vac칤os (NaN)
    - NO existen usuarios con datos parcialmente completados

    丘멆잺 Implicaci칩n: La imputaci칩n de estos valores podr칤a ser problem치tica
       debido a que el 93% de los usuarios no proporcionaron esta informaci칩n.
:::
:::

::: {#6801ff7d .cell .markdown}
# 3. Integraci칩n de Datasets {#3-integraci칩n-de-datasets}
:::

::: {#9802e0ad .cell .markdown}
## 3.1. Explicaci칩n de la L칩gica de Join {#31-explicaci칩n-de-la-l칩gica-de-join}

Para crear un dataset unificado, seguimos esta l칩gica:

1.  Explotar pedidos: Cada item pedido se convierte en una fila
2.  Merge con usuarios: A침adir informaci칩n demogr치fica
3.  Merge con inventory: A침adir detalles del producto
4.  Calcular campos de regulars: Cantidad de veces que un item es
    regular para un usuario
5.  Calcular campos de abandoned_carts: Cantidad de veces que un item
    fue abandonado por un usuario
:::

::: {#fca021d5 .cell .code execution_count="109"}
``` python
# 1. Explotar 칩rdenes
groceries_df = orders_df.explode('ordered_items')
groceries_df = groceries_df.rename(columns={'ordered_items': 'item_id'})

# 2. Merge con usuarios
groceries_df = pd.merge(groceries_df, users_df, on='user_id', how='left')

# 3. Merge con inventory
groceries_df = pd.merge(groceries_df, inventory_df, 
                       left_on='item_id', right_on='variant_id', how='left')

# 4. Calcular campos de regulars
regulars_count = regulars_df.groupby(['user_id', 'variant_id']).size().reset_index(name='regular_count')
groceries_df = pd.merge(groceries_df, regulars_count,
                       left_on=['user_id', 'item_id'],
                       right_on=['user_id', 'variant_id'], how='left')
groceries_df['regular_count'] = groceries_df['regular_count'].fillna(0).astype(int)

# 5. Calcular campos de abandoned_carts
abandoned_items = abandoned_carts_df.explode('variant_id')
abandoned_count = abandoned_items.groupby(['user_id', 'variant_id']).size().reset_index(name='abandoned_count')
groceries_df = pd.merge(groceries_df, abandoned_count,
                       left_on=['user_id', 'item_id'],
                       right_on=['user_id', 'variant_id'], how='left')
groceries_df['abandoned_count'] = groceries_df['abandoned_count'].fillna(0).astype(int)

# Limpiar columnas duplicadas
groceries_df = groceries_df.drop(columns=['variant_id_x', 'variant_id_y', 'variant_id'])

print(f"Dataset final: {groceries_df.shape}")
print(f"Columnas disponibles: {', '.join(groceries_df.columns)}")
```

::: {.output .stream .stdout}
    Dataset final: (107958, 26)
    Columnas disponibles: id, user_id, created_at, order_date, user_order_seq, item_id, num_items, weekday, user_segment, user_nuts1, first_ordered_at, customer_cohort_month, count_people, count_adults, count_children, count_babies, count_pets, nans_in_group, price, compare_at_price, vendor, product_type, tags, discount_percent, regular_count, abandoned_count
:::
:::

::: {#6865325a .cell .markdown}
# 4. An치lisis Avanzados {#4-an치lisis-avanzados}
:::

::: {#f5cda960 .cell .markdown}
## 4.1. Comportamiento de Compra Regular {#41-comportamiento-de-compra-regular}
:::

::: {#3103dde8 .cell .code execution_count="110"}
``` python
regulars_popularity = regulars_df['variant_id'].value_counts().head(10)

top_regulars = pd.merge(regulars_popularity.reset_index(), 
                       inventory_df[['variant_id', 'vendor', 'product_type']], 
                       on='variant_id')

plt.figure(figsize=(12, 6))
plt.barh(range(len(top_regulars)), top_regulars['count'], color='skyblue')
plt.yticks(range(len(top_regulars)), 
           [f"{row['vendor']} ({row['product_type']})" for _, row in top_regulars.iterrows()])
plt.xlabel('Frecuencia')
plt.title('Top 10 Items Marcados como Compra Regular')
plt.tight_layout()
plt.show()
```

::: {.output .display_data}
![](vertopal_14d689f6814c4519ba3c7ab29e27ed07/17bf814ab398f4aaf5695f3d74c328e7d6805378.png)
:::
:::

::: {#639e7f5a .cell .markdown}
## 4.2. Patr칩n de Abandono de Carrito {#42-patr칩n-de-abandono-de-carrito}
:::

::: {#49213ac0 .cell .code execution_count="111"}
``` python
category_abandonment = {}

for category in inventory_df['product_type'].unique():

    category_items = inventory_df[inventory_df['product_type'] == category]['variant_id']
    
    ordered = groceries_df[groceries_df['item_id'].isin(category_items)].shape[0]
    
    abandoned_items_exploded = abandoned_carts_df.explode('variant_id')
    abandoned = abandoned_items_exploded[
        abandoned_items_exploded['variant_id'].isin(category_items)
    ].shape[0]
    
    if ordered + abandoned > 0:
        conversion_rate = ordered / (ordered + abandoned)
        category_abandonment[category] = conversion_rate

# Visualizar ratio de conversi칩n
abandoned_df = pd.DataFrame.from_dict(category_abandonment, orient='index', columns=['conversion_rate'])
abandoned_df = abandoned_df.sort_values('conversion_rate', ascending=False).head(10)

plt.figure(figsize=(12, 6))
abandoned_df['conversion_rate'].plot(kind='bar')
plt.title('Tasa de Conversi칩n por Categor칤a (Top 10)', fontsize=14)
plt.xlabel('Categor칤a')
plt.ylabel('Tasa de Conversi칩n')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()
```

::: {.output .display_data}
![](vertopal_14d689f6814c4519ba3c7ab29e27ed07/f7cbe1343c0e836cd41a70f0be2541e83c5f8c60.png)
:::
:::

::: {#4411374c .cell .markdown}
# Conclusiones

No he tenido principales hip칩tesis al empezar la tarea. He entrado en un
rabbit hole investigando cada variable de cada dataset, pero sin ver el
problema desde otra perspectiva y sin fijarme objetivos.

En cambio, investigando he sacando algunas conclusiones:

1.  Hay 640 items comprados de los que no tenemos informaci칩n en el
    inventario
2.  El 21 de Enero de 2022 hay un pico en el n칰mero de pedidos
3.  El 6 de Enero de 2022 hay un outlier en n칰mero de items en un pedido
4.  El 93.5% no tiene informaci칩n demogr치fica

Vista la soluci칩n de Guille, me he dado cuenta que es muy importante
analizar el problema de forma cr칤tica y con una visi칩n m치s enfocada en
el negocio. Es decir, dejar a un lado el c칩digo y ponerse el la piel de
un CEO:

-   쯈uien me compra?
-   쯈u칠 productos quieren los clientes?
-   쮺u치l es el patron de compra?

Veo que este paso me ha costado, y me he quedado en un muy simple
analisis sin conclusiones importantes.
:::
